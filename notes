- in current directory make a new folder named the series name - and make sure invalid charecters are not saved as folder name
- in that folder make cbz files for each chapter

if a folder in the name of the series already exists only download chapters that are not already in that folder
- first check if there isn't a folder in current directory named our series, then check if current directory itself is not named after our series - then make a new folder in current directory that is our series

use a folder, download pictures inside, create a cbr from files in folder
^call this folder working directory - create on every run, delete at end of every run

when download done - run this in working directory - run bach -c
zip ../(chapter name here).cbr *
rm -rf ./

if -v is applied print when a chapter finishes downloading
and also print each picture download like 3/36 and then zipping, and then done - make sure updates on same line with \r and if last message longer than next have enough spaces to remove it
don't forget to fflush

support kissmanga
and hitomi

gotta deal with cookies - keep a struct, and with challenge responses, do everytime 503 comes up, if after sending fails, ask again for webpage and don't send cookie info

do not fully impliment cookies - but put that as a thing to do, for now get it up and running :P

comment all methods
and global variables

also allow options like download from 000 ect.
and if they put in a chapter download from that chapter onwards ect.

allow for multiple urls
- loop through each argument and change variable accordingly
- make -v have to be last
- folder to save 2nd last if -v otherwise last

create a list of chapter structs then go through said structs

what if instead of series just a chapter page is given - then just download the chapter

clean up code!!

quick fail downloading chapters - and move on don't exit

keep auto-updating desired mangas - just run the url every day automatically or whatever

figure out images about joining scans and remove them - basiclly by hashing and comparing hashes, whatever repeats delete
