- in current directory make a new folder named the series name - and make sure invalid charecters are not saved as folder name
- in that folder make cbz files for each chapter

if a folder in the name of the series already exists only download chapters that are not already in that folder
- first check if there isn't a folder in current directory named our series, then check if current directory itself is not named after our series - then make a new folder in current directory that is our series

use a folder, download pictures inside, create a cbr from files in folder
^call this folder working directory - create on every run, delete at end of every run

comment all methods
and global variables

also allow options like download from 000 ect.
and if they put in a chapter download from that chapter onwards ect.

allow for multiple urls
- loop through each argument and change variable accordingly
- make -v have to be last
- folder to save 2nd last if -v otherwise last

what if instead of series just a chapter page is given - then just download the chapter

clean up code!!

quick fail downloading chapters - and move on don't exit

keep auto-updating desired mangas - just run the url every day automatically or whatever
store somewhere where to update from and so if you just run tmdl in that folder it'll just work on updating it

figure out images about joining scans and remove them - basiclly by hashing and comparing hashes, whatever repeats delete

-d disables deleting what it thinks Is doubled up data, makes faster, -e makes double up check extensive 
-hashmap of md5-hashes of pictures and location
-at first duplicate, unzip folder delete file, rezip, remove location data from hashmap, and delete the just downloaded file, if duplicate found and location is null, only delete new one
-try to keep the hashmap small, so after say 10 chapters all the hashes with locations in them, we can discard it, -e prevents this discard
-at the end we save the hashmap to a hidden file in the folder .duplicatehashset
-also provide a function, so you go into the folder and just run the program and it'll update the chapters - store settings in hidden file .settings here also goes site it came from
- if new url run in the folder - update the .settings file given the name of the magnga ends up the same

- keep some kind of auto updater?

-Make sure kissmanga side of things is kept seperate from the rest of the program

- use a binary search tree for the hashmap so when I search if something alreayd exists I can do it in log n time!

thread the mapcheccking

improve the verbose print
improve the name of the image and the extension it is saved as

impliment download of a single chapter kissMangaDownload.c:78

make a massive defines file for all the places I search for in source code to get stuff so if the site changes its easier to update

create an md5sum file .md5 and read from it and append to it, so every time a new image downloads, get the md5 of it, then check if it already exists in avl tree, if not add to tree and append to file
also save the md5s in the file so it can be easy to constrct in O(n) time
make avl tree

also make my own tries or suffix trees for my own searching through website source code

make universal avl tree that takes void * and uses a compare function

predessor search succesor search, dictionary look up - just a predessor wrapper

    /**
     * Check for additional content type reading first few characters from the given input stream.
     * 
     * @return the guessed MIME-type or null if the type could not be determined.
     */
    private String guessAdditionalContentTypeFromStream(InputStream is)
    {
        String mt = null;

        if (is != null) {
            try {

                // Look ahead up to 64 bytes for the longest encoded header
                is.mark(64);
                byte[] bytes = new byte[64];
                int length = is.read(bytes);
                is.reset();
                if (length == -1) {
                    return null;
                }
                if (bytes[0] == 'G' && bytes[1] == 'I' && bytes[2] == 'F' && bytes[3] == '8') {
                    mt = "image/gif";
                } else if (bytes[0] == (byte) 0x89 && bytes[1] == (byte) 0x50 && bytes[2] == (byte) 0x4E
                    && bytes[3] == (byte) 0x47 && bytes[4] == (byte) 0x0D && bytes[5] == (byte) 0x0A
                    && bytes[6] == (byte) 0x1A && bytes[7] == (byte) 0x0A) {
                    mt = "image/png";
                } else if (bytes[0] == (byte) 0xFF && bytes[1] == (byte) 0xD8 && bytes[2] == (byte) 0xFF) {
                    if ((bytes[3] == (byte) 0xE0)
                        || (bytes[3] == (byte) 0xE1 && bytes[6] == 'E' && bytes[7] == 'x' && bytes[8] == 'i'
                            && bytes[9] == 'f' && bytes[10] == 0)) {
                        mt = "image/jpeg";
                    } else if (bytes[3] == (byte) 0xEE) {
                        mt = "image/jpg";
                    }
                }
            } catch (Exception e) {
                Log.e(TAG, e.getMessage(), e, Log.DEBUG_MODE);
            }
        }
        return mt;
}
